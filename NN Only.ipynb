{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code pour le Baseline Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, LSTM, RepeatVector, TimeDistributed, Dropout\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Dropout\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax.experimental.ode import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial # reduces arguments to function by making some subset implicit\n",
    "\n",
    "from jax.example_libraries import stax\n",
    "from jax.example_libraries import optimizers\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from functools import partial\n",
    "import proglog\n",
    "\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des fonctions pour générer les trajectoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la durée et la fonction de génération de trajectoire\n",
    "duree = np.linspace(0, 20, num=401)\n",
    "\n",
    "def generate_trajectory(initial):\n",
    "    trajectory = jax.device_get(solve_analytical(initial, duree))\n",
    "    return trajectory\n",
    "\n",
    "# Fonction pour générer le dataset\n",
    "def generate_dataset(num_samples, duree):\n",
    "    dataset = []\n",
    "    for i in range(num_samples):\n",
    "        # Générer des conditions initiales aléatoires\n",
    "        theta1 = np.random.uniform(-np.pi/2, np.pi/2)\n",
    "        omega1 = 0\n",
    "        theta2 = np.random.uniform(-np.pi/2, np.pi/2)\n",
    "        omega2 = 0\n",
    "        initial = np.array([theta1, theta2, omega1, omega2], dtype=np.float32)\n",
    "\n",
    "        try:\n",
    "            # Générer la trajectoire\n",
    "            trajectory = generate_trajectory(initial)  # Forme: (301, 4)\n",
    "\n",
    "            # Ajouter au dataset\n",
    "            dataset.append({\n",
    "                'initial_conditions': initial,\n",
    "                'trajectory': trajectory\n",
    "            })\n",
    "        except RuntimeError:\n",
    "            # Ignorer les échecs d'intégration\n",
    "            continue\n",
    "\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print(f\"{i+1} échantillons générés...\")\n",
    "    return dataset\n",
    "\n",
    "# Générer le dataset (peut prendre du temps en fonction de num_samples)\n",
    "num_samples = 5000\n",
    "dataset = generate_dataset(num_samples, duree)\n",
    "print(f'Dataset généré avec {len(dataset)} échantillons.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on veut sauvegarder le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sauvegarder le dataset\n",
    "with open('double_pendulum_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(dataset, f)\n",
    "\n",
    "#Charger le dataset (si nécessaire)\n",
    "with open('double_pendulum_dataset.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons une donné du dataset pour voir si c'est ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = np.array([np.pi/4, np.pi/4, 0, 0], dtype=np.float32)\n",
    "trajectory = jax.device_get(solve_analytical(initial, duree))\n",
    "\n",
    "plt.plot(duree, trajectory[:,1])\n",
    "\n",
    "traj_bis = generate_trajectory(initial)\n",
    "plt.plot(duree, traj_bis[:,1], '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supposons que votre dataset est déjà généré et stocké dans la variable `dataset`\n",
    "# Si vous avez sauvegardé le dataset, décommentez les lignes suivantes pour le charger\n",
    "# with open('double_pendulum_dataset.pkl', 'rb') as f:\n",
    "#     dataset = pickle.load(f)\n",
    "\n",
    "# Vérifiez si le dataset contient des échantillons\n",
    "if len(dataset) == 0:\n",
    "    print(\"Le dataset est vide. Veuillez vérifier la génération des données.\")\n",
    "else:\n",
    "    # Choisir un échantillon à visualiser\n",
    "    sample_idx = 100  # Vous pouvez changer cet index pour visualiser d'autres échantillons\n",
    "    sample = dataset[sample_idx]\n",
    "    initial_conditions = sample['initial_conditions']\n",
    "    trajectory = sample['trajectory']  # Forme: (301, 4)\n",
    "\n",
    "    print(f\"Conditions initiales : {initial_conditions}\")\n",
    "    #print(f\"Trajectoire : {trajectory}\")\n",
    "\n",
    "    # Extraire les valeurs de theta1, omega1, theta2, omega2\n",
    "    theta1 = trajectory[:, 0]\n",
    "    omega1 = trajectory[:, 2]\n",
    "    theta2 = trajectory[:, 1]\n",
    "    omega2 = trajectory[:, 3]\n",
    "\n",
    "    # Tracer les angles et les vitesses angulaires au fil du temps\n",
    "    plt.figure(figsize=(14, 10))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(duree, theta1, label=r'$\\theta_1$ (rad)')\n",
    "    plt.plot(duree, theta2, label=r'$\\theta_2$ (rad)')\n",
    "    plt.title('Angles du Double Pendule en Fonction du Temps')\n",
    "    plt.xlabel('Temps (s)')\n",
    "    plt.ylabel('Angle (rad)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(duree, omega1, label=r'$\\omega_1$ (rad/s)')\n",
    "    plt.plot(duree, omega2, label=r'$\\omega_2$ (rad/s)')\n",
    "    plt.title('Vélocités Angulaires du Double Pendule en Fonction du Temps')\n",
    "    plt.xlabel('Temps (s)')\n",
    "    plt.ylabel('Vitesse Angulaire (rad/s)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optionnel : Tracer les trajectoires des angles entre eux\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(theta1, theta2, label='Trajectoire Angulaire')\n",
    "    plt.title('Trajectoire Angulaire du Double Pendule')\n",
    "    plt.xlabel(r'$\\theta_1$ (rad)')\n",
    "    plt.ylabel(r'$\\theta_2$ (rad)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prépare les données pour l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données\n",
    "X = np.array([sample['initial_conditions'] for sample in dataset])  # Forme: (num_samples, 4)\n",
    "y = np.array([sample['trajectory'] for sample in dataset])         # Forme: (num_samples, 301, 4)\n",
    "print(f'X shape: {X.shape}, y shape: {y.shape}')\n",
    "\n",
    "# Normalisation\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "num_samples, timesteps, features = y.shape\n",
    "y_reshaped = y.reshape(-1, features)  # Forme: (num_samples * timesteps, 4)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y_reshaped).reshape(num_samples, timesteps, features)\n",
    "\n",
    "# Séparation train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "print(f'Entraînement: {X_train.shape}, Test: {X_test.shape}')\n",
    "\n",
    "# Définir les dimensions\n",
    "input_dim = X_train.shape[1]          # 4\n",
    "output_timesteps = y_train.shape[1]   # 301\n",
    "output_features = y_train.shape[2]    # 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit l'architecture du NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le modèle\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(input_dim,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(RepeatVector(output_timesteps))\n",
    "model.add(LSTM(256, return_sequences=True, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=True, activation='tanh'))\n",
    "model.add(TimeDistributed(Dense(output_features)))\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualiser l'entraînement\n",
    "plt.plot(history.history['loss'], label='Entraînement')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.legend()\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Entraînement du Modèle')\n",
    "plt.show()\n",
    "\n",
    "# Évaluer le modèle\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f'Loss sur le jeu de test : {test_loss}')\n",
    "\n",
    "# Faire des prédictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Inverser la normalisation\n",
    "predictions_inv = scaler_y.inverse_transform(predictions.reshape(-1, output_features)).reshape(predictions.shape)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, output_features)).reshape(y_test.shape)\n",
    "\n",
    "# Visualiser une séquence\n",
    "sequence_idx = 0\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "labels = ['θ1', 'θ2', 'ω1', 'ω2']\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.plot(y_test_inv[sequence_idx, :, i], label=f'{labels[i]} réel')\n",
    "    plt.plot(predictions_inv[sequence_idx, :, i], label=f'{labels[i]} prédit', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Pas de temps')\n",
    "    plt.ylabel(labels[i])\n",
    "    plt.title(f'Comparaison de {labels[i]} réel et prédit')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait les prédictions avec des nouvelles data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Définir vos propres conditions initiales\n",
    "custom_initial = np.array([np.pi/4, 0, 0, 0], dtype=np.float32)\n",
    "print(\"Conditions Initiales Personnalisées:\", custom_initial)\n",
    "\n",
    "# 2. Normaliser les conditions initiales\n",
    "custom_initial_scaled = scaler_X.transform(custom_initial.reshape(1, -1))  # Forme: (1, 4)\n",
    "print(\"Conditions Initiales Normalisées:\", custom_initial_scaled)\n",
    "\n",
    "# 3. Faire la prédiction\n",
    "predicted_scaled = model.predict(custom_initial_scaled)  # Forme: (1, 301, 4)\n",
    "print(\"Prédiction Normalisée Shape:\", predicted_scaled.shape)\n",
    "\n",
    "# 4. Inverser la normalisation\n",
    "predicted_inv = scaler_y.inverse_transform(predicted_scaled.reshape(-1, 4)).reshape(predicted_scaled.shape)  # Forme: (1, 301, 4)\n",
    "print(\"Prédiction Inversée Shape:\", predicted_inv.shape)\n",
    "\n",
    "# 5. Visualiser la trajectoire prédite\n",
    "duree = np.linspace(0, 20, num=301)  # Assurez-vous que 'duree' est défini\n",
    "\n",
    "trajectory_pred = predicted_inv[0]  # Forme: (301, 4)\n",
    "\n",
    "# 6. (Optionnel) Comparer avec une trajectoire réelle\n",
    "# Générer la trajectoire réelle\n",
    "actual_trajectory = generate_trajectory(custom_initial)  # Forme: (301, 4)\n",
    "print(\"Trajectoire Réelle Shape:\", actual_trajectory.shape)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.plot(duree, actual_trajectory[:, i], label='Réel', color='blue', alpha=0.4)\n",
    "    plt.plot(duree, trajectory_pred[:, i], label='Prédit', color='orange', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Temps (s)')\n",
    "    plt.ylabel(f'{labels[i]} ({units[i]})')\n",
    "    plt.title(f'Comparaison de {labels[i]} Réel et Prédit')\n",
    "    plt.grid(True)\n",
    "\n",
    "# Ajouter les conditions initiales comme une annotation globale\n",
    "plt.suptitle(\n",
    "    f'Conditions Initiales:\\n'\n",
    "    f'θ1 = {custom_initial[0]:.2f} rad, θ2 = {custom_initial[1]:.2f} rad\\n'\n",
    "    f'ω1 = {custom_initial[2]:.2f} rad/s, ω2 = {custom_initial[3]:.2f} rad/s',\n",
    "    fontsize=16,\n",
    "    y=0.95\n",
    ")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.93])  # Ajuster l'espace pour la super-titre\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions l'énergie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_energy(th1, th2, w1, w2, m1=1, m2=1, l1=1, l2=1, g=9.8):\n",
    "\n",
    "  T = 0.5*(m1 + m2)*l1**2*w1**2 + 0.5*m2*l2**2*w2**2 + m2*l1*l2*w1*w2*jnp.cos(th1 - th2)\n",
    "  V = (m1+m2)*g*l1*jnp.cos(th1) + m2*g*l2*jnp.cos(th2)\n",
    "\n",
    "  return T - V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_analytique = check_energy(actual_trajectory[:,0], actual_trajectory[:,1], actual_trajectory[:,2], actual_trajectory[:,3])\n",
    "energy_pred = check_energy(trajectory_pred[:,0], trajectory_pred[:,1], trajectory_pred[:,2], trajectory_pred[:,3])\n",
    "plt.plot(duree, energy_analytique, label='Energie Analytique')\n",
    "plt.plot(duree, energy_pred, label='Energie Baseline NN')\n",
    "\n",
    "plt.xlabel(r'Temps (s)')\n",
    "plt.ylabel(r'Energie (J)')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
